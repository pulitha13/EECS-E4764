{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (List of 2D numpy arrays):\n",
      "(80, 304)\n",
      "Y (List of first letters):\n",
      "(80,)\n"
     ]
    }
   ],
   "source": [
    "# Folder containing the CSV files\n",
    "folder_path = \"Letters/data\"\n",
    "\n",
    "# Initialize empty list for X (list of 2D arrays) and Y (list of first letters)\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Read the CSV file using pandas\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        data = pd.read_csv(file_path, header=None)  # header=None if the CSV doesn't have column headers\n",
    "\n",
    "        # Convert the pandas DataFrame to a numpy array and append to X\n",
    "        X.append(data.to_numpy()[:, 0:-1])\n",
    "\n",
    "        # Get the first letter of the filename and append to Y\n",
    "        Y.append(data.to_numpy()[0, -1])  # Assuming the first letter is the label\n",
    "\n",
    "# PREPROCESS\n",
    "\n",
    "# Find the minimum number of rows\n",
    "min_rows = min(el.shape[0] for el in X)\n",
    "\n",
    "# Truncate each array to have only `min_rows` rows\n",
    "truncated_data = [el[:min_rows, :] for el in X]\n",
    "X = truncated_data\n",
    "\n",
    "# Convert X to a numpy array\n",
    "X = np.array(X).astype(float)\n",
    "\n",
    "# Define different scalers for different columns\n",
    "scaler_first_column = MinMaxScaler(feature_range=(0, 1))  # Scaling first column to [0, 1]\n",
    "scaler_other_column = MinMaxScaler(feature_range=(-1, 1))  # Scaling first column to [0, 1]\n",
    "\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    X[i, :, 0:1] = scaler_first_column.fit_transform(X[i, :, 0:1])\n",
    "    X[i, :, 1:] = scaler_other_column.fit_transform(X[i, :, 1:])\n",
    "\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "Y = np.array(Y).astype(str)\n",
    "\n",
    "# Print the results\n",
    "print(\"X (List of 2D numpy arrays):\")\n",
    "print(X.shape)\n",
    "    \n",
    "print(\"Y (List of first letters):\")\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test\n",
    "labels = ['c', 'o', 'l', 'u', 'm', 'b', 'i', 'a']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=24, shuffle=True, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypertraining (SKIP THIS IF IT TAKES TOO LONG)\n",
    "labels = ['c', 'o', 'l', 'u', 'm', 'b', 'i', 'a']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=24, shuffle=True, stratify=Y)\n",
    "\n",
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \n",
    "\t      \"min_samples_leaf\" : [1, 5, 10], \n",
    "\t      \"min_samples_split\" : [2, 4, 10, 12], \n",
    "\t      \"n_estimators\": [400, 700, 1000]\n",
    "}\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "rf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=1, n_jobs=-1)\n",
    "clf = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oob score: 87.5 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 3, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 3, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 2],\n",
       "       [0, 1, 0, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 2, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 2]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(criterion = \"gini\", \n",
    "                                       n_estimators=1000,\n",
    "\t\t\t\t       min_samples_leaf=1,\n",
    "\t\t\t\t       min_samples_split=4,\n",
    "                                       oob_score=True, \n",
    "                                       random_state=1, \n",
    "                                       n_jobs=-1)\n",
    "\n",
    "random_forest.fit(x_train, y_train)\n",
    "y_prediction = random_forest.predict(x_test)\n",
    "\n",
    "random_forest.score(x_test, y_test)\n",
    "\n",
    "print(\"oob score:\", round(random_forest.oob_score_, 4)*100, \"%\")\n",
    "\n",
    "predictions = cross_val_predict(random_forest, x_test, y_test, cv=3)\n",
    "confusion_matrix(y_test, predictions, labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# Here you can replace pickle with joblib or cloudpickle\n",
    "from pickle import dump\n",
    "with open(\"model_v0.pkl\", \"wb\") as f:\n",
    "    dump(random_forest, f, protocol=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
